# PaPE2021
Software and data supporting Lilley &amp; Bunnell paper presented to Phonetics and Phonology in Europe (PaPE) 2021, June 23. This work is an advancement of the work presented at InterSpeech 2021.

In the interest of having accurate and complete scientific records, these files are completely identical to the ones used for the research reported in that manuscript, except that (1) additional comments have been added, and (2) code used only to evaluate the models on data other than TIMIT data has been removed.

## Model training:

The Python code used to train the models, and run them on the evaluation data, are provided as both Jupyter notebook files (\*.ipynb) and executable Python scripts (\*.py). TensorFlow 2.3 or above is required to run them. The provided script **LSTM1\_noIAIF\_DFLoss** contains the code used for the non-IAIF models described in this presentation, including (1) the option to use either pre-emphasis or no source model, and (2) the optional use of delta-frequency loss.

Note that the code makes some assumptions based on the circumstances of our computational setup at the time; one would need to edit the code accordingly for their own setup. We intend to provide a more uniform and user-friendly version of the code for general use soon.

### Execution:

Each script is run with 5 command-line parameters; see documentation within the script for details. Output consisting of data statistics, model specifications, and script progress reports, including training and validation loss, can be saved to an output file, e.g.:

> LSTM1_noIAIF_DFLoss.py 6 1 T F 10 > LSTM1DF.f6z1TF10.out

On a GPU it takes us about 4 hours total to run; on a CPU, it may take half a day or more to run.

### Input:

The script looks for the two provided files, timwavs_ordered2.txt and VTRlist1.txt, which are file lists of the TIMIT dataset (Garofolo et al. 1993) and the VTR Formants database (Deng et al. 2006) respectively. The script will then look for the input data files listed in these lists in the locations specified in the script. Unlike the IS2021 scripts, this script runs directly on the raw TIMIT wavefiles (which we cannot provide), extracting and computing the input spectral envelopes as the files are processed.


### Output:

The output models and evaluation files will be saved in a directory with a name like mvt33\_f6z1TF10/ (where the first part, e.g. "mvt33", is a unique designation for the script, and the second part, e.g. "f6z1TF10" indicates the selected command-line parameters. The model files (stored in tensorflow model weight format, consisting of a data file and an index file) are stored directly in this directory. A subdirectory, e.g. mvt23_f6z1TF10/timit/, will hold the output formant track files, one for each input file.

The output formant track files are stored as text files with the suffix .abs. The following is the first few lines from an example output file (with values rounded to 1 place after the decimal point, for brevity):

> test\_dr1\_felc0\_si1386 AA 1 1 0.0 200.0 60 0 0 60 40 2 7   578.0 346.4 -20.5 1081.1 235.4 -27.2 2435.6 760.9 -30.0 3267.7 732.1 -28.2 4501.1 1276.0 -31.2 6511.0 2621.8 -42.5 -3026.4 4877.2 0.0  
> test\_dr1\_felc0\_si1386 AA 1 1 5.0 200.0 60 0 0 60 40 2 7   683.5 229.3 -19.6 953.2 269.2 -19.7 2644.0 851.6 -26.1 3158.2 383.5 -32.2 4267.3 556.6 -35.8 6737.9 2716.3 -41.8 -1850.0 4717.65 0.0  
> test\_dr1\_felc0\_si1386 AA 1 1 10.0 200.0 60 0 0 60 40 2 7   718.8 237.9 -18.1 946.5 333.1 -20.0 2728.7 566.0 -29.6 3144.7 285.4 -36.7 4302.6 539.9 -38.1 7174.0 1398.4 -48.1 -1329.9 4069.2 0.0  

This format was designed for the specific interests of our laboratory; the first 12 columns are placeholders for parameters of interest of us to be filled in later, with the exception of column 1 (the input filename), and column 4, the frame's time-stamp. Note that our input files were generated at a 5-msec frame rate, and so the time stamps are filled in assuming a 5-msec frame rate (this can be easily changed in the script).

Column 13 indicates the total number of resonances (7 here: 6 poles and 1 zero). Following column 13 are the actual predicted formant estimates, in the order F1 B1 A1, F2 B2 A2, etc. -- first the poles, in order of increasing mean frequency, and then zeros, in order of increasing absolute mean frequency. Note that the zeros are given a negative frequency to distinguish them from the poles, and the meaningless placeholder value "0.0" inserted for their amplitudes (which are not estimated by the model).

Note that the formant track parameters generated by these Python scripts are not smoothed; the binomial smoothing described in our manuscript was done by the evaluation scripts, as described below.


## Evaluation scripts

Further scripts have been provided in the ../IS2021 directory, which (1) compile all the estimated frequencies in the .abs files into a single file, and (2) run statistical analyses of the frequencies against the VTR Formant database. Again, these files are identical to those used for the IS 2021 analysis, except with the addition of extra commentary. See the README page in the ../IS2021 directory for more details about these scripts and the input files they need to function. 

## References:

* J. Lilley and H. T. Bunnell, "Unsupervised training of a DNN-based formant tracker," manuscript to appear in *Interspeech 2021*.
* Y. Dissen, J. Goldberger, and J. Keshet, “Formant estimation and tracking: A deep learning approach,” *Journal of the Acoustical Society of America*, vol. 145, no. 2, pp. 642-653, Feb. 2019.
* L. Deng, X. Cui, R. Pruvenok, Y. Chen, S. Momen, and A. Alwan, “A database of vocal tract resonance trajectories for research in speech processing,” in *Proceedings of ICASSP 2006—IEEE International Conference on Acoustics, Speech and Signal Processing*, vol. 1, pp. I-I, 2006.  Database downloaded from http://www.seas.ucla.edu/spapl/VTRFormants.html
* J. S. Garofolo, L. F. Lamel, W. M. Fisher, J. G. Fiscus, D. S. Pallett, N. L. Dahlgren, and V. Zue, *The DARPA TIMIT acoustic-phonetic continuous speech corpus*. Linguistic Data Consortium, 1993.
