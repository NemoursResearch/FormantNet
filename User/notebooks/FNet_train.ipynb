{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FormantNet Training Script (user-friendly version)\n",
    "\n",
    "This script is a user-friendly version of the code used in the IS2021 and PaPE2021 papers. It can be used as an executable script to train a FormantNet model, as described below. The trained model can then be run on test wavefiles to generate formant tracks with the companion script **FNet_track.py**. (Alternatively, one may use **FormantNet.py** to do both training and tracking at the same time.)\n",
    "\n",
    "### Prerequisites:\n",
    "These scripts require Python 3 and NumPy, as well as Tensorflow (2.3 or later) and all of its dependencies. They also require the supplied supporting code files (FN_configuration.py, FN_data.py, and FN_model.py). If possible, set it up to run on a GPU (or TPU -- tensor processing unit), which will be much faster than on a conventional CPU. For example, our experiments with the TIMIT dataset (including both training and tracking) would take at least 12 hours on a CPU, and sometimes multiple days, but would only take about 4 hours on our GPU (most of which was actually for data loading and evaluation -- your GPU setup may be even faster).\n",
    "\n",
    "### Use:\n",
    "For use on the command line, the syntax for this script is summarized as follows, where square brackets indicate optional elements:\n",
    "\n",
    "**python3 FNet_train.py** *[**-h**] [**-c** config] [**-v** validlist] modeldir trainlist*\n",
    "\n",
    "In other words, there are 2 required arguments: the name of a directory in which to store the trained model (*modeldir*), and a text file (*trainlist*) listing the training files (with full pathnames). With the flags, the user may also optionally specify a configuration file and a validation file list. The -h (\"help\") option will print a summary of this information to the screen. \n",
    "\n",
    "Note that the script will also print a bunch of information (including the full configuration, data statistics, model architecture summary, training progress, and per-epoch loss values) to the screen, which can be redirected to a file in the usual ways, e.g.:\n",
    "\n",
    "**python3 FNet_all.py -v timit_valid.txt my_FNet_model timit_train.txt > FNet_traininglog.txt**\n",
    "\n",
    "See the README file in this directory for more information about the use of this script, the output file format, and the various options available via the configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import FN_configuration\n",
    "import FN_data\n",
    "import FN_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set JUPYTER_WINDOW to True if you want to run this script as a notebook in e.g. Jupyter. Note that input files will have to be specified manually below. Also note below that cfg.TESTRUN will be set to True.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JUPYTER_WINDOW = True\n",
    "#JUPYTER_WINDOW = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JUPYTER_WINDOW:\n",
    "    configfile = 'FNet_config0.txt'\n",
    "    modeldir = 'ft2_model'\n",
    "    trainlistfile = 'timit_train.txt'\n",
    "    validlistfile = 'timit_valid.txt'\n",
    "    #validlistfile = None\n",
    "\n",
    "else:\n",
    "    parser = argparse.ArgumentParser(description=\"Train a FormantNet model.\")\n",
    "    parser.add_argument(\"modeldir\", help=\"Directory to save model files in\")\n",
    "    parser.add_argument(\"trainlist\", help=\"List of training files\")\n",
    "    parser.add_argument(\"-v\", \"--validlist\", help=\"List of validation files\")\n",
    "    parser.add_argument(\"-c\", \"--config\", help=\"Configuration file\")\n",
    "    \n",
    "    args = parser.parse_args()    \n",
    "    configfile = args.config\n",
    "    modeldir = args.modeldir\n",
    "    trainlistfile = args.trainlist\n",
    "    validlistfile = args.validlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = FN_configuration.configuration()\n",
    "cfg.configure(configfile)\n",
    "\n",
    "if JUPYTER_WINDOW:\n",
    "    cfg.TESTRUN = True\n",
    "\n",
    "with open(trainlistfile) as f:\n",
    "    trainlist = [i[:-1] for i in list(f)]\n",
    "\n",
    "if validlistfile is not None:\n",
    "    with open(validlistfile) as f:\n",
    "        validlist = [i[:-1] for i in list(f)]\n",
    "else:\n",
    "    validlist = None\n",
    "\n",
    "if cfg.TESTRUN:\n",
    "    modeldir = \"tmp_\" + modeldir\n",
    "    trainlist = trainlist[:50]\n",
    "    if validlist is not None:\n",
    "        validlist = validlist[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFORMANTNET script FNet_train.py: Train a neural-network model for formant tracking.\")\n",
    "print(\"\\nSUMMARY OF FILES AND DIRECTORIES:\")\n",
    "print(\"Test Run:\", cfg.TESTRUN)\n",
    "print(\"\\nTraining file list: {} ({} files)\".format(trainlistfile, len(trainlist)))\n",
    "if validlist is None:\n",
    "    print(\"Validation file list: None\")\n",
    "else:    \n",
    "    print(\"Validation file list: {} ({} files)\".format(validlistfile, len(validlist)))\n",
    "print(\"Model directory:\", modeldir)\n",
    "print(\"Configuration file:\", configfile)\n",
    "cfg.report_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLoading training data ....\")\n",
    "sys.stdout.flush()\n",
    "batched_train_dset, trmean, trstd = FN_data.get_batched_data(trainlist, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validlist is not None:  \n",
    "    print(\"\\nLoading validation data ....\")\n",
    "    sys.stdout.flush()\n",
    "    batched_val_dset, mn, sd = FN_data.get_batched_data(validlist, cfg, trmean, trstd)\n",
    "else:\n",
    "    batched_val_dset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FN_model.define_model(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN_model.train_model(model, modeldir, cfg, batched_train_dset, batched_val_dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set statistics are saved to a text file in the model directory so they can be used to normalize future test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(modeldir + \"/Normfile\", \"w\") as f:\n",
    "    f.write(str(trmean) + '\\n')\n",
    "    f.write(str(trstd) + '\\n')\n",
    "    \n",
    "print(\"\\nSaving mean and standard deviation of training data to model directory (\" + modeldir + \"/Normfile\" + \"):\")\n",
    "print(\"Mean:\", trmean)\n",
    "print(\"Standard Deviation:\", trstd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore best model and calculate overall loss on training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = tf.train.latest_checkpoint(modeldir)\n",
    "model.load_weights(latest)\n",
    "print(\"\\nRestoring model\", latest)\n",
    "sys.stdout.flush()\n",
    "\n",
    "train_eval = model.evaluate(batched_train_dset, verbose=0)\n",
    "print(\"Training loss:\", train_eval[0])\n",
    "sys.stdout.flush()\n",
    "\n",
    "if validlist is not None:\n",
    "    val_eval = model.evaluate(batched_val_dset, verbose=0)\n",
    "    print(\"Validation loss:\", val_eval[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFINISHED training script for\", modeldir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
