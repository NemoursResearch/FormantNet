{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FormantNet Tracking Script (user-friendly version)\n",
    "\n",
    "This script is a user-friendly version of the code used in the IS2021 and PaPE2021 papers. It can be used as an executable script to run a FormantNet model (that has been trained by either **FormantNet.py** or **FNet_train.py**) on test wavefiles to generate predicted formant tracks.  (Alternatively, one may use **FormantNet.py** to do both training and tracking at the same time.)\n",
    "\n",
    "### Prerequisites:\n",
    "These scripts require Python 3 and NumPy, as well as Tensorflow (2.3 or later) and all of its dependencies. They also require the supplied supporting code files (FN_configuration.py, FN_data.py, and FN_model.py). If possible, set it up to run on a GPU (or TPU -- tensor processing unit), which will be much faster than on a conventional CPU. For example, our experiments with the TIMIT dataset (including both training and tracking) would take at least 12 hours on a CPU, and sometimes multiple days, but would only take about 4 hours on our GPU (most of which was actually for data loading and evaluation -- your GPU setup may be even faster).\n",
    "\n",
    "### Use:\n",
    "For use on the command line, the syntax for this script is summarized as follows, where square brackets indicate optional elements:\n",
    "\n",
    "**python3 FNet_track.py** *[**-h**] [**-c** config] [**-o** outdir] modeldir testlist*\n",
    "\n",
    "In other words, there are 2 required arguments: the name of the directory in which the trained model can be found (*modeldir*), and a text file (*testlist*) listing the files to be tracked (with full pathnames). With the flags, the user may also optionally specify a configuration file and an output directory in which to store the text files that will hold the predicted formant tracks. If no output directory is specified, then each output file is written to the same directory as the input wavefile. The -h (\"help\") option will print a summary of this information to the screen. \n",
    "\n",
    "Note that the script will also print a bunch of information (including the full configuration, data statistics, model architecture summary, and evaluation progress) to the screen, which can be redirected to a file in the usual ways, e.g.:\n",
    "\n",
    "**python3 FNet_track.py -o my_FNet_results my_FNet_model timit_test.txt > FNet_trackinglog.txt**\n",
    "\n",
    "See the README file in this directory for more information about the use of this script, the output file format, and the various options available via the configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import FN_configuration\n",
    "import FN_data\n",
    "import FN_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set JUPYTER_WINDOW to True if you want to run this script as a notebook in e.g. Jupyter. Note that input files will have to be specified manually below. Also note below that cfg.TESTRUN will be set to True.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JUPYTER_WINDOW = True\n",
    "#JUPYTER_WINDOW = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JUPYTER_WINDOW:\n",
    "    configfile = 'FNet_config0.txt'\n",
    "    modeldir = 'ft2_model'\n",
    "    testlistfile = 'timit_test.txt'\n",
    "    #testlistfile = 'VTRlist3.txt'\n",
    "    outdir = 'ft2_out'\n",
    "    #outdir = None\n",
    "\n",
    "else:\n",
    "    parser = argparse.ArgumentParser(description=\"Run a trained FormantNet model on a test set.\")\n",
    "    parser.add_argument(\"modeldir\", help=\"Directory holding saved model\")\n",
    "    parser.add_argument(\"testlist\", help=\"List of test files\")\n",
    "    parser.add_argument(\"-o\", \"--outdir\", help=\"Directory to save test output files in [Default: input dir(s)]\")\n",
    "    parser.add_argument(\"-c\", \"--config\", help=\"Configuration file\")\n",
    "    \n",
    "    args = parser.parse_args()    \n",
    "    configfile = args.config\n",
    "    modeldir = args.modeldir\n",
    "    outdir = args.outdir\n",
    "    testlistfile = args.testlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = FN_configuration.configuration()\n",
    "cfg.configure(configfile)\n",
    "\n",
    "if JUPYTER_WINDOW:\n",
    "    cfg.TESTRUN = True\n",
    "\n",
    "with open(testlistfile) as f:\n",
    "    testlist = [i[:-1] for i in list(f)]\n",
    "\n",
    "if cfg.TESTRUN:\n",
    "    modeldir = \"tmp_\" + modeldir\n",
    "    testlist = testlist[:10]\n",
    "    if outdir is not None:\n",
    "        outdir = \"tmp_\" + outdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFORMANTNET script FNet_track.py: Test a formant-tracking neural-network model on new wavefiles.\")\n",
    "print(\"\\nSUMMARY OF FILES AND DIRECTORIES:\")\n",
    "print(\"Test Run:\", cfg.TESTRUN)\n",
    "print(\"\\nTest file list: {} ({} files)\".format(testlistfile, len(testlist)))\n",
    "print(\"Model directory:\", modeldir)\n",
    "if outdir is None:\n",
    "    print(\"Output directory: None (output tracking files redirected to wavefile directory/ies)\")\n",
    "else:\n",
    "    print(\"Output directory:\", outdir)\n",
    "print(\"Configuration file:\", configfile)\n",
    "cfg.report_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FN_model.define_model(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved model weights and calculate overall loss on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = tf.train.latest_checkpoint(modeldir)\n",
    "model.load_weights(latest)\n",
    "print(\"\\nRestoring model\", latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to testing, we need to normalize the test data with the mean and standard deviation of the training set. These stats are saved in a file called \"Normfile\" in the model directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(modeldir + \"/Normfile\", \"r\") as f:\n",
    "    trmean = float(f.readline())\n",
    "    trstd = float(f.readline())\n",
    "\n",
    "print(\"\\nReloading mean and standard deviation of training data from model directory (\" + modeldir + \"/Normfile\" + \"):\")\n",
    "print(\"Mean:\", trmean)\n",
    "print(\"Standard Deviation:\", trstd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the test data is loaded into a tf.data.Dataset, the data statistics are computed, and the model loss is calculated with respect to the test data.  Note that the test data is loaded again, as individual files, during tracking below, so the test data is effectively loaded twice. Thus, if you have a large dataset and slow machine, and are not interested in the statistics or loss value, it may make sense to skip this step by setting cfg.GET_TEST_LOSS to false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.GET_TEST_LOSS:\n",
    "    print(\"\\nLoading test data ....\")\n",
    "    sys.stdout.flush()\n",
    "    batched_test_dset, mn, sd = FN_data.get_batched_data(testlist, cfg, trmean, trstd)\n",
    "\n",
    "    test_eval = model.evaluate(batched_test_dset, verbose=0)\n",
    "    print(\"\\nTest loss:\", test_eval[0])\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate formant tracks on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN_model.track_files(testlist, model, trmean, trstd, cfg, outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFINISHED tracking script for files in\", testlistfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
